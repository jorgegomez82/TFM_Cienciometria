# ğŸ“Š TFM CienciometrÃ­a
**Ãndice de novedad en publicaciones cientÃ­ficas del campo de las matemÃ¡ticas**

Este proyecto forma parte del Trabajo de Fin de MÃ¡ster y tiene como objetivo **estimar un Ã­ndice de novedad en artÃ­culos cientÃ­ficos del Ã¡rea de matemÃ¡ticas**, a partir del anÃ¡lisis semÃ¡ntico de tÃ­tulos y resÃºmenes.  
Se utilizan enfoques de **Word2Vec** y **MathBERT**, junto con tÃ©cnicas de cienciometrÃ­a.

---

## ğŸ“‚ Estructura del repositorio

```
TFM_Cienciometria/
â”œâ”€â”€ data/                  # Conjuntos de datos (NO versionados en GitHub, se guardan en Zenodo)
â”‚   â”œâ”€â”€ raw/               # Descargas iniciales desde la API de Scopus (por dÃ©cadas)
â”‚   â”œâ”€â”€ enriquecido/       # Datos enriquecidos con metadatos adicionales
â”‚   â”œâ”€â”€ word2Vec/tmp/      # Resultados intermedios de Word2Vec
â”‚   â”œâ”€â”€ mathbert/tmp/      # Resultados intermedios de MathBERT
â”‚   â””â”€â”€ tmp_articulos_abstract/
â”œâ”€â”€ scripts/               # Scripts de procesamiento
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ word2Vec/      # Scripts para pipeline Word2Vec
â”‚   â”‚   â”œâ”€â”€ mathbert/      # Notebook especÃ­fico de MathBERT
â”‚   â”‚   â”‚   â””â”€â”€ 04_mathbert_vectorizar.ipynb   # Se ejecuta en Colab
â”‚   â”‚   â”œâ”€â”€ 05_computar_novedad_word2vec_mathbert.ipynb  # Se ejecuta en Colab
â”‚   â”‚   â””â”€â”€ 06_visualizar_novedad_word2vec_mathbert.ipynb # Se ejecuta en Colab
â”‚   â””â”€â”€ recoleccionDatosAPI/ # Descarga desde API de Scopus
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ ignorar.gitignore
```

---

## âš™ï¸ InstalaciÃ³n

1. Clona el repositorio:
   ```bash
   git clone https://github.com/usuario/TFM_Cienciometria.git
   cd TFM_Cienciometria
   ```

2. Crea un entorno virtual e instala dependencias:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   venv\Scripts\activate     # Windows

   pip install -r requirements.txt
   ```

3. **Modelos externos necesarios**:
   - Modelo de idioma FastText (`lid.176.ftz`) se descarga automÃ¡ticamente en `/idioma_modelo/` cuando se ejecuta `01_filter_language.py`.
   - Modelo de spaCy:
     ```bash
     python -m spacy download en_core_web_sm
     ```

---

## ğŸš€ Pipeline de procesamiento

### 1. RecolecciÃ³n de datos desde Scopus
Los scripts en `/scripts/recoleccionDatosAPI/` descargan y enriquecen los artÃ­culos:
```bash
python scripts/recoleccionDatosAPI/searchAPI/main_06.py
python scripts/recoleccionDatosAPI/abstractAPI/enriquecer_desde_eid.py
```

### 2. Preprocesamiento de abstracts (Word2Vec)
```bash
cd scripts/embeddings/word2Vec

# Filtrado por idioma (usa FastText)
python 01_filter_language.py --todo

# Preprocesamiento y bigramas
python 02_preprocess_text.py --todo

# Entrenamiento Word2Vec
python 03_train_word2vec.py --todo

# VectorizaciÃ³n de documentos
python 04_vectorizar_word2vec.py --todo
```

### 3. VectorizaciÃ³n con MathBERT
En `/scripts/embeddings/mathbert/`, se ejecuta en Google Colab:
- **`04_mathbert_vectorizar.ipynb`**

### 4. CÃ¡lculo de novedad (Word2Vec + MathBERT)
Los dos notebooks compartidos para ambos enfoques (ejecutar en Colab):
- **`05_computar_novedad_word2vec_mathbert.ipynb`**
- **`06_visualizar_novedad_word2vec_mathbert.ipynb`**

---

## ğŸ’¾ Datos en Zenodo
Debido al gran tamaÃ±o, los datasets no se incluyen en GitHub.  
Se almacenan en **Zenodo**, organizados en carpetas comprimidas:

- `raw/` â†’ datos originales de Scopus (por dÃ©cadas)
- `enriquecido/` â†’ datos enriquecidos con metadatos
- `word2Vec/tmp/` â†’ modelos entrenados y vectores
- `mathbert/tmp/` â†’ embeddings y resultados intermedios

Cada carpeta en Zenodo incluye un archivo `README.txt` explicativo.

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.XXXXXXX.svg)](https://doi.org/10.5281/zenodo.XXXXXXX)

---

## ğŸ“‘ Requisitos principales
- `fasttext==0.9.2`
- `gensim==4.3.3`
- `spacy==3.8.7`
- `torch==2.5.0`
- `transformers==4.44.2`
- `pandas`, `numpy`, `tqdm`, `matplotlib`, `seaborn`

(Ver [requirements.txt](requirements.txt) para la lista completa).

---

## âœ¨ CrÃ©ditos
Trabajo de Fin de MÃ¡ster en CienciometrÃ­a.  
Autor: Jorge GÃ³mez GÃ³mez