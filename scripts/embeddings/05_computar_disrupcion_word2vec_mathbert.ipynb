{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b11f75a1d09b46d6bb429ec199e1f8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Seleccione un modelo",
              "mathbert",
              "word2vec"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Modelo:",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_dc46d5e446e245bc9e1d6b630fbffb1b",
            "style": "IPY_MODEL_7578bd208b414a93ad84f85727824614"
          }
        },
        "dc46d5e446e245bc9e1d6b630fbffb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7578bd208b414a93ad84f85727824614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Celda de Configuración Inicial para Google Colab\n",
        "# ==========================================================\n",
        "# Ejecuta esta celda al principio de tu notebook cada vez que inicies una nueva sesión.\n",
        "\n",
        "# --- 1. Conectar a Google Drive ---\n",
        "# Aparecerá una ventana para que autorices el acceso a tus archivos.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n✅ Google Drive conectado exitosamente.\")\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlmnM_LhNy76",
        "outputId": "d340ce5b-089e-4468-8a85-2acac1c91761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "✅ Google Drive conectado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# SECCIÓN DE CONFIGURACIÓN INTERACTIVA\n",
        "# ==========================================================\n",
        "\n",
        "# Opción 1: Menú Desplegable (RECOMENDADO)\n",
        "model_options = ['Seleccione un modelo', 'mathbert', 'word2vec']\n",
        "model_selector = widgets.Dropdown(\n",
        "    options=model_options,\n",
        "    value=model_options[0],\n",
        "    description='Modelo:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "print(\"Por favor, selecciona un modelo para el cual calcular el Índice KI y luego ejecuta la celda de abajo.\")\n",
        "display(model_selector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b11f75a1d09b46d6bb429ec199e1f8f1",
            "dc46d5e446e245bc9e1d6b630fbffb1b",
            "7578bd208b414a93ad84f85727824614"
          ]
        },
        "id": "sSF-G-JTZqlu",
        "outputId": "29ebdf07-f903-4b15-d92e-c57906502bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, selecciona un modelo para el cual calcular el Índice KI y luego ejecuta la celda de abajo.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Modelo:', options=('Seleccione un modelo', 'mathbert', 'word2vec'), value='Seleccione un…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b11f75a1d09b46d6bb429ec199e1f8f1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6Rs1FhsEaOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6562a5d-2100-4263-d5a6-703c16553d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo seleccionado: word2vec\n",
            "✅ Ventana de cálculo para KI: 5 años (pasado y futuro)\n",
            "==================================================\n",
            "INICIANDO CÁLCULO PARA EL MODELO: word2vec\n",
            "CARGANDO VECTORES DESDE: /content/drive/MyDrive/TFM_Cienciometria/data/word2vec/tmp/04_vectores_word2vec_TODO.pkl\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 1. CONFIGURACIÓN\n",
        "# ==========================================================\n",
        "DRIVE_PROJECT_PATH = '/content/drive/MyDrive/TFM_Cienciometria'\n",
        "MODEL_NAME = model_selector.value\n",
        "\n",
        "# --- PARÁMETROS DEL ÍNDICE KI ---\n",
        "# [cite_start]Ventana de 5 años hacia atrás y 5 hacia adelante, como en el paper [cite: 243]\n",
        "YEARS_WINDOW = 5\n",
        "\n",
        "# --- PARÁMETRO DE OPTIMIZACIÓN ---\n",
        "# 8192 o 16384 son buenos valores para una A100.\n",
        "BATCH_SIZE = 16384\n",
        "\n",
        "print(f\"✅ Modelo seleccionado: {MODEL_NAME}\")\n",
        "print(f\"✅ Ventana de cálculo para KI: {YEARS_WINDOW} años (pasado y futuro)\")\n",
        "\n",
        "# Configurar rutas y directorios basados en la selección\n",
        "if MODEL_NAME == 'mathbert':\n",
        "    TMP_DIR = os.path.join(DRIVE_PROJECT_PATH, 'data/mathbert/tmp')\n",
        "elif MODEL_NAME == 'word2vec':\n",
        "    TMP_DIR = os.path.join(DRIVE_PROJECT_PATH, 'data/word2vec/tmp')\n",
        "else:\n",
        "    # Este bloque se ejecuta si no se ha seleccionado un modelo válido\n",
        "    pass\n",
        "\n",
        "# ==========================================================\n",
        "# 2. LÓGICA DE CÁLCULO DEL ÍNDICE KI SEMÁNTICO\n",
        "# ==========================================================\n",
        "def compute_ki_semantic(df: pd.DataFrame, years_window: int, batch_size: int):\n",
        "    \"\"\"\n",
        "    Calcula el Índice KI Semántico usando una ventana temporal simétrica (pasado/futuro)\n",
        "    y vectores de embeddings pre-calculados. El cálculo se optimiza para GPU.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"🚀 Realizando cálculos del Índice KI en {device} con precisión FP16 y BATCH_SIZE={batch_size}\")\n",
        "\n",
        "    # --- Pre-cálculos de fechas y ORDENAMIENTO CRÍTICO ---\n",
        "    df['cover_date'] = pd.to_datetime(df['cover_date'], errors=\"coerce\")\n",
        "    df = df.dropna(subset=['cover_date', 'vector']).sort_values(by=[\"cover_date\", \"eid\"]).reset_index(drop=True)\n",
        "    print(\"✅ DataFrame ordenado por 'cover_date' y 'eid'.\")\n",
        "\n",
        "    # Convertir fechas a números para búsquedas rápidas con NumPy\n",
        "    dates_ordinal = df['cover_date'].apply(lambda x: x.toordinal()).to_numpy()\n",
        "\n",
        "    # Determinar el rango de fechas procesable para tener ventanas completas\n",
        "    time_delta = pd.Timedelta(days=365.25 * years_window)\n",
        "    min_date = df['cover_date'].min() + time_delta\n",
        "    max_date = df['cover_date'].max() - time_delta\n",
        "\n",
        "    # Filtrar para procesar solo los artículos que tienen datos suficientes\n",
        "    processing_mask = (df['cover_date'] >= min_date) & (df['cover_date'] <= max_date)\n",
        "    processing_indices = df.index[processing_mask].to_numpy()\n",
        "\n",
        "    print(f\"ℹ️  Corpus total: {len(df)} artículos.\")\n",
        "    print(f\"✅ Se procesarán {len(processing_indices)} artículos entre {min_date.date()} y {max_date.date()} para garantizar ventanas completas.\")\n",
        "\n",
        "    # --- Carga y normalización de vectores en la GPU ---\n",
        "    V = np.vstack(df[\"vector\"].values).astype(np.float32)\n",
        "    V_gpu = torch.from_numpy(V).to(device, dtype=torch.float16)\n",
        "    V_gpu = V_gpu / torch.norm(V_gpu, dim=1, keepdim=True).clamp(min=1e-12)\n",
        "\n",
        "    results = []\n",
        "    desc = f\"🔍 Calculando KI Semántico (Ventana={years_window} años)\"\n",
        "\n",
        "    # Bucle principal por lotes (solo sobre los índices procesables)\n",
        "    for i in tqdm(range(0, len(processing_indices), batch_size), desc=desc):\n",
        "        batch_indices = processing_indices[i : i + batch_size]\n",
        "\n",
        "        for j in batch_indices:\n",
        "            target_vector = V_gpu[j]\n",
        "            current_date_ord = dates_ordinal[j]\n",
        "            window_days = time_delta.days\n",
        "\n",
        "            # --- Ventana PASADA ---\n",
        "            past_start_ord = current_date_ord - window_days\n",
        "            start_idx = np.searchsorted(dates_ordinal, past_start_ord, side='left')\n",
        "            past_indices = np.arange(start_idx, j)\n",
        "\n",
        "            if len(past_indices) > 0:\n",
        "                past_sims = (V_gpu[past_indices] @ target_vector + 1) / 2\n",
        "                sum_past_sim = torch.sum(past_sims, dtype=torch.float32).clamp(min=1e-9) # Clamp para evitar división por cero\n",
        "            else:\n",
        "                sum_past_sim = torch.tensor(1e-9, device=device)\n",
        "\n",
        "            # --- Ventana FUTURA ---\n",
        "            future_end_ord = current_date_ord + window_days\n",
        "            end_idx = np.searchsorted(dates_ordinal, future_end_ord, side='right')\n",
        "            future_indices = np.arange(j + 1, end_idx)\n",
        "\n",
        "            if len(future_indices) > 0:\n",
        "                future_sims = (V_gpu[future_indices] @ target_vector + 1) / 2\n",
        "                sum_future_sim = torch.sum(future_sims, dtype=torch.float32).clamp(min=1e-9)\n",
        "            else:\n",
        "                sum_future_sim = torch.tensor(1e-9, device=device)\n",
        "\n",
        "            # --- Cálculo del Índice KI Semántico ---\n",
        "            ki_score = torch.log(sum_future_sim / sum_past_sim)\n",
        "\n",
        "            results.append({\n",
        "                \"eid\": df.at[j, \"eid\"],\n",
        "                \"ki_score\": ki_score.item(),\n",
        "                \"past_pool_size\": len(past_indices),\n",
        "                \"future_pool_size\": len(future_indices)\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# ==========================================================\n",
        "# 3. EJECUCIÓN PRINCIPAL\n",
        "# ==========================================================\n",
        "if __name__ == '__main__':\n",
        "    if MODEL_NAME != 'Seleccione un modelo':\n",
        "        t0 = time.time()\n",
        "        BASE = \"TODO\"\n",
        "\n",
        "        # Generar nombres de archivo\n",
        "        input_path = os.path.join(TMP_DIR, f\"04_vectores_{MODEL_NAME}_{BASE}.pkl\")\n",
        "        output_suffix = f\"05_ki_semantic_{MODEL_NAME}_{BASE}_win{YEARS_WINDOW}\"\n",
        "        csv_output = os.path.join(TMP_DIR, f\"{output_suffix}.csv\")\n",
        "        pkl_output = os.path.join(TMP_DIR, f\"{output_suffix}.pkl\")\n",
        "\n",
        "        print(\"=\"*50)\n",
        "        print(f\"INICIANDO CÁLCULO PARA EL MODELO: {MODEL_NAME}\")\n",
        "        print(f\"CARGANDO VECTORES DESDE: {input_path}\")\n",
        "        print(\"=\"*50)\n",
        "        df_main = pd.read_pickle(input_path)\n",
        "\n",
        "        # --- LLAMADA A LA FUNCIÓN DE CÁLCULO ---\n",
        "        ki_df = compute_ki_semantic(\n",
        "            df=df_main,\n",
        "            years_window=YEARS_WINDOW,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        print(\"\\n📊 Resumen del Índice KI Semántico:\")\n",
        "        if not ki_df.empty:\n",
        "            print(ki_df['ki_score'].describe())\n",
        "        else:\n",
        "            print(\"No se generaron resultados. Revisa el rango de fechas de tu corpus.\")\n",
        "\n",
        "        print(\"\\n💾 Guardando resultados...\")\n",
        "        meta_cols = [c for c in [\"eid\", \"title\", \"cover_date\", \"citedby_count\", \"doi\"] if c in df_main.columns]\n",
        "        # Usamos 'inner' join para quedarnos solo con los artículos para los que se pudo calcular el KI\n",
        "        final_df = df_main[meta_cols].merge(ki_df, on=\"eid\", how=\"inner\")\n",
        "\n",
        "        final_df.to_csv(csv_output, index=False)\n",
        "        final_df.to_pickle(pkl_output)\n",
        "\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"\\n✅ Resultados guardados en:\\n- {csv_output}\\n- {pkl_output}\")\n",
        "        print(f\"⏱️  Tiempo total: {elapsed/60:.2f} min\")\n",
        "    else:\n",
        "        print(\"⚠️ Por favor, selecciona un modelo en el menú desplegable y vuelve a ejecutar la celda.\")"
      ]
    }
  ]
}