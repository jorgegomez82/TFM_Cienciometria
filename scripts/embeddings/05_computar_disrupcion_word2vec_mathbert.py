# -*- coding: utf-8 -*-
"""05_computar_disrupcion_word2vec_mathbert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18SN1aOz3YWvYOWul69PnNP7KD7Yw-Bgg
"""

# ==========================================================
# Celda de Configuraci√≥n Inicial para Google Colab
# ==========================================================
# Ejecuta esta celda al principio de tu notebook cada vez que inicies una nueva sesi√≥n.

# --- 1. Conectar a Google Drive ---
# Aparecer√° una ventana para que autorices el acceso a tus archivos.
from google.colab import drive
drive.mount('/content/drive')
print("\n‚úÖ Google Drive conectado exitosamente.")

import os
import time
import pickle
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm
import torch
import ipywidgets as widgets
from IPython.display import display

# ==========================================================
# SECCI√ìN DE CONFIGURACI√ìN INTERACTIVA
# ==========================================================

# Opci√≥n 1: Men√∫ Desplegable (RECOMENDADO)
model_options = ['Seleccione un modelo', 'mathbert', 'word2vec']
model_selector = widgets.Dropdown(
    options=model_options,
    value=model_options[0],
    description='Modelo:',
    disabled=False,
)

print("Por favor, selecciona un modelo para el cual calcular el √çndice KI y luego ejecuta la celda de abajo.")
display(model_selector)

# ==========================================================
# 1. CONFIGURACI√ìN
# ==========================================================
DRIVE_PROJECT_PATH = '/content/drive/MyDrive/TFM_Cienciometria'
MODEL_NAME = model_selector.value

# --- PAR√ÅMETROS DEL √çNDICE KI ---
# [cite_start]Ventana de 5 a√±os hacia atr√°s y 5 hacia adelante, como en el paper [cite: 243]
YEARS_WINDOW = 5

# --- PAR√ÅMETRO DE OPTIMIZACI√ìN ---
# 8192 o 16384 son buenos valores para una A100.
BATCH_SIZE = 16384

print(f"‚úÖ Modelo seleccionado: {MODEL_NAME}")
print(f"‚úÖ Ventana de c√°lculo para KI: {YEARS_WINDOW} a√±os (pasado y futuro)")

# Configurar rutas y directorios basados en la selecci√≥n
if MODEL_NAME == 'mathbert':
    TMP_DIR = os.path.join(DRIVE_PROJECT_PATH, 'data/mathbert/tmp')
elif MODEL_NAME == 'word2vec':
    TMP_DIR = os.path.join(DRIVE_PROJECT_PATH, 'data/word2vec/tmp')
else:
    # Este bloque se ejecuta si no se ha seleccionado un modelo v√°lido
    pass

# ==========================================================
# 2. L√ìGICA DE C√ÅLCULO DEL √çNDICE KI SEM√ÅNTICO
# ==========================================================
def compute_ki_semantic(df: pd.DataFrame, years_window: int, batch_size: int):
    """
    Calcula el √çndice KI Sem√°ntico usando una ventana temporal sim√©trica (pasado/futuro)
    y vectores de embeddings pre-calculados. El c√°lculo se optimiza para GPU.
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üöÄ Realizando c√°lculos del √çndice KI en {device} con precisi√≥n FP16 y BATCH_SIZE={batch_size}")

    # --- Pre-c√°lculos de fechas y ORDENAMIENTO CR√çTICO ---
    df['cover_date'] = pd.to_datetime(df['cover_date'], errors="coerce")
    df = df.dropna(subset=['cover_date', 'vector']).sort_values(by=["cover_date", "eid"]).reset_index(drop=True)
    print("‚úÖ DataFrame ordenado por 'cover_date' y 'eid'.")

    # Convertir fechas a n√∫meros para b√∫squedas r√°pidas con NumPy
    dates_ordinal = df['cover_date'].apply(lambda x: x.toordinal()).to_numpy()

    # Determinar el rango de fechas procesable para tener ventanas completas
    time_delta = pd.Timedelta(days=365.25 * years_window)
    min_date = df['cover_date'].min() + time_delta
    max_date = df['cover_date'].max() - time_delta

    # Filtrar para procesar solo los art√≠culos que tienen datos suficientes
    processing_mask = (df['cover_date'] >= min_date) & (df['cover_date'] <= max_date)
    processing_indices = df.index[processing_mask].to_numpy()

    print(f"‚ÑπÔ∏è  Corpus total: {len(df)} art√≠culos.")
    print(f"‚úÖ Se procesar√°n {len(processing_indices)} art√≠culos entre {min_date.date()} y {max_date.date()} para garantizar ventanas completas.")

    # --- Carga y normalizaci√≥n de vectores en la GPU ---
    V = np.vstack(df["vector"].values).astype(np.float32)
    V_gpu = torch.from_numpy(V).to(device, dtype=torch.float16)
    V_gpu = V_gpu / torch.norm(V_gpu, dim=1, keepdim=True).clamp(min=1e-12)

    results = []
    desc = f"üîç Calculando KI Sem√°ntico (Ventana={years_window} a√±os)"

    # Bucle principal por lotes (solo sobre los √≠ndices procesables)
    for i in tqdm(range(0, len(processing_indices), batch_size), desc=desc):
        batch_indices = processing_indices[i : i + batch_size]

        for j in batch_indices:
            target_vector = V_gpu[j]
            current_date_ord = dates_ordinal[j]
            window_days = time_delta.days

            # --- Ventana PASADA ---
            past_start_ord = current_date_ord - window_days
            start_idx = np.searchsorted(dates_ordinal, past_start_ord, side='left')
            past_indices = np.arange(start_idx, j)

            if len(past_indices) > 0:
                past_sims = (V_gpu[past_indices] @ target_vector + 1) / 2
                sum_past_sim = torch.sum(past_sims, dtype=torch.float32).clamp(min=1e-9) # Clamp para evitar divisi√≥n por cero
            else:
                sum_past_sim = torch.tensor(1e-9, device=device)

            # --- Ventana FUTURA ---
            future_end_ord = current_date_ord + window_days
            end_idx = np.searchsorted(dates_ordinal, future_end_ord, side='right')
            future_indices = np.arange(j + 1, end_idx)

            if len(future_indices) > 0:
                future_sims = (V_gpu[future_indices] @ target_vector + 1) / 2
                sum_future_sim = torch.sum(future_sims, dtype=torch.float32).clamp(min=1e-9)
            else:
                sum_future_sim = torch.tensor(1e-9, device=device)

            # --- C√°lculo del √çndice KI Sem√°ntico ---
            ki_score = torch.log(sum_future_sim / sum_past_sim)

            results.append({
                "eid": df.at[j, "eid"],
                "ki_score": ki_score.item(),
                "past_pool_size": len(past_indices),
                "future_pool_size": len(future_indices)
            })

    return pd.DataFrame(results)

# ==========================================================
# 3. EJECUCI√ìN PRINCIPAL
# ==========================================================
if __name__ == '__main__':
    if MODEL_NAME != 'Seleccione un modelo':
        t0 = time.time()
        BASE = "TODO"

        # Generar nombres de archivo
        input_path = os.path.join(TMP_DIR, f"04_vectores_{MODEL_NAME}_{BASE}.pkl")
        output_suffix = f"05_ki_semantic_{MODEL_NAME}_{BASE}_win{YEARS_WINDOW}"
        csv_output = os.path.join(TMP_DIR, f"{output_suffix}.csv")
        pkl_output = os.path.join(TMP_DIR, f"{output_suffix}.pkl")

        print("="*50)
        print(f"INICIANDO C√ÅLCULO PARA EL MODELO: {MODEL_NAME}")
        print(f"CARGANDO VECTORES DESDE: {input_path}")
        print("="*50)
        df_main = pd.read_pickle(input_path)

        # --- LLAMADA A LA FUNCI√ìN DE C√ÅLCULO ---
        ki_df = compute_ki_semantic(
            df=df_main,
            years_window=YEARS_WINDOW,
            batch_size=BATCH_SIZE
        )

        print("\nüìä Resumen del √çndice KI Sem√°ntico:")
        if not ki_df.empty:
            print(ki_df['ki_score'].describe())
        else:
            print("No se generaron resultados. Revisa el rango de fechas de tu corpus.")

        print("\nüíæ Guardando resultados...")
        meta_cols = [c for c in ["eid", "title", "cover_date", "citedby_count", "doi"] if c in df_main.columns]
        # Usamos 'inner' join para quedarnos solo con los art√≠culos para los que se pudo calcular el KI
        final_df = df_main[meta_cols].merge(ki_df, on="eid", how="inner")

        final_df.to_csv(csv_output, index=False)
        final_df.to_pickle(pkl_output)

        elapsed = time.time() - t0
        print(f"\n‚úÖ Resultados guardados en:\n- {csv_output}\n- {pkl_output}")
        print(f"‚è±Ô∏è  Tiempo total: {elapsed/60:.2f} min")
    else:
        print("‚ö†Ô∏è Por favor, selecciona un modelo en el men√∫ desplegable y vuelve a ejecutar la celda.")