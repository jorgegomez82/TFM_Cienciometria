{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e84da4233364951a227b754ddf34903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "mathbert",
              "word2vec"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Modelo:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_4d1b78958e704946a37ca7bd7f07da80",
            "style": "IPY_MODEL_99684c16e54341da9150f9dd0530ccbf"
          }
        },
        "4d1b78958e704946a37ca7bd7f07da80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99684c16e54341da9150f9dd0530ccbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a267621460d7476b93fca85da215bbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2abb9d4dd8344940a523c22ff4e8a524",
              "IPY_MODEL_3abe07077b1c441880e703a229d376a7",
              "IPY_MODEL_9cb8d5ca8364430ca69e57937fb6fc0b"
            ],
            "layout": "IPY_MODEL_e114e4742b394185a84d20efff20ce2c"
          }
        },
        "2abb9d4dd8344940a523c22ff4e8a524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab748a3ee4a6473eadd79200d29bbc7a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_eb46f6feddd34405b62fb1db4ce19401",
            "value": "üîç‚ÄáNovedad‚ÄáH√çBRIDA-GPU‚Äá(K=150000,‚ÄáM=120):‚Äá100%"
          }
        },
        "3abe07077b1c441880e703a229d376a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d40294adec14b00bb165081b2c3f1b6",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fad9bbe25ba749d2aab6668255bf391e",
            "value": 75
          }
        },
        "9cb8d5ca8364430ca69e57937fb6fc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4c2803c5b9841888cb7436a326d1819",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_776b21ab84374c2fb154d2be58e289b2",
            "value": "‚Äá75/75‚Äá[29:57&lt;00:00,‚Äá23.25s/it]"
          }
        },
        "e114e4742b394185a84d20efff20ce2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab748a3ee4a6473eadd79200d29bbc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb46f6feddd34405b62fb1db4ce19401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d40294adec14b00bb165081b2c3f1b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad9bbe25ba749d2aab6668255bf391e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4c2803c5b9841888cb7436a326d1819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776b21ab84374c2fb154d2be58e289b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Celda de Configuraci√≥n Inicial para Google Colab\n",
        "# ==========================================================\n",
        "# Ejecuta esta celda al principio de tu notebook cada vez que inicies una nueva sesi√≥n.\n",
        "\n",
        "# --- 1. Conectar a Google Drive ---\n",
        "# Aparecer√° una ventana para que autorices el acceso a tus archivos.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n‚úÖ Google Drive conectado exitosamente.\")\n",
        "\n",
        "# --- 2. Instalar Paquetes Necesarios ---\n",
        "# Usamos -q para una instalaci√≥n \"silenciosa\" (menos texto de salida).\n",
        "# 'transformers' es la librer√≠a de Hugging Face para usar MathBERT.\n",
        "# 'accelerate' ayuda a optimizar la ejecuci√≥n en el hardware de Colab.\n",
        "print(\"\\nüì¶ Instalando librer√≠as necesarias...\")\n",
        "!pip install -q transformers accelerate\n",
        "print(\"‚úÖ Librer√≠as instaladas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlmnM_LhNy76",
        "outputId": "9a1b6f2d-f998-4342-b75a-7cf24f9f419d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "‚úÖ Google Drive conectado exitosamente.\n",
            "\n",
            "üì¶ Instalando librer√≠as necesarias...\n",
            "‚úÖ Librer√≠as instaladas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "mIBcKhV1ZoP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# SECCI√ìN DE CONFIGURACI√ìN INTERACTIVA\n",
        "# ==========================================================\n",
        "\n",
        "# Opci√≥n 1: Men√∫ Desplegable (RECOMENDADO)\n",
        "# Es mejor porque evita errores al escribir el nombre del modelo.\n",
        "model_selector = widgets.Dropdown(\n",
        "    options=['mathbert', 'word2vec'],\n",
        "    value='mathbert', # Valor por defecto\n",
        "    description='Modelo:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "print(\"Por favor, selecciona el modelo a procesar y luego ejecuta las celdas de abajo.\")\n",
        "display(model_selector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "3e84da4233364951a227b754ddf34903",
            "4d1b78958e704946a37ca7bd7f07da80",
            "99684c16e54341da9150f9dd0530ccbf"
          ]
        },
        "id": "sSF-G-JTZqlu",
        "outputId": "7a2383cd-9727-46a4-ba00-37e0bbd93661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, selecciona el modelo a procesar y luego ejecuta las celdas de abajo.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Modelo:', options=('mathbert', 'word2vec'), value='mathbert')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e84da4233364951a227b754ddf34903"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "a267621460d7476b93fca85da215bbd5",
            "2abb9d4dd8344940a523c22ff4e8a524",
            "3abe07077b1c441880e703a229d376a7",
            "9cb8d5ca8364430ca69e57937fb6fc0b",
            "e114e4742b394185a84d20efff20ce2c",
            "ab748a3ee4a6473eadd79200d29bbc7a",
            "eb46f6feddd34405b62fb1db4ce19401",
            "4d40294adec14b00bb165081b2c3f1b6",
            "fad9bbe25ba749d2aab6668255bf391e",
            "f4c2803c5b9841888cb7436a326d1819",
            "776b21ab84374c2fb154d2be58e289b2"
          ]
        },
        "id": "R6Rs1FhsEaOj",
        "outputId": "4256bb23-795c-40e3-dd78-dba9598a2630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo seleccionado: word2vec\n",
            "üì¶ Cargando vectores desde: /content/drive/MyDrive/TFM_Cienciometria/data/word2vec/tmp/04_vectores_word2vec_TODO.pkl\n",
            "üß† Calculando √≠ndices de novedad (Optimizado H√≠brido para A100)...\n",
            "üöÄ Realizando c√°lculos H√çBRIDOS en cuda con precisi√≥n FP16 y BATCH_SIZE=16384\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "üîç Novedad H√çBRIDA-GPU (K=150000, M=120):   0%|          | 0/75 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a267621460d7476b93fca85da215bbd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Resumen de novedad por percentil:\n",
            "    p0: count=1213939 mean=0.0647 std=0.0238 min=-0.0010 max=0.5654\n",
            "    p5: count=1213939 mean=0.2025 std=0.0474 min=0.0648 max=0.5669\n",
            "    p10: count=1213939 mean=0.2293 std=0.0502 min=0.0919 max=0.5903\n",
            "    p20: count=1213939 mean=0.2645 std=0.0532 min=0.1118 max=0.6211\n",
            "\n",
            "üíæ Guardando resultados...\n",
            "\n",
            "‚úÖ Resultados guardados en:\n",
            "- /content/drive/MyDrive/TFM_Cienciometria/data/word2vec/tmp/05_novelty_scores_word2vec_TODO_p0_5_10_20_k150000_m120_strict_pool50000.csv\n",
            "- /content/drive/MyDrive/TFM_Cienciometria/data/word2vec/tmp/05_novelty_scores_word2vec_TODO_p0_5_10_20_k150000_m120_strict_pool50000.pkl\n",
            "‚è±Ô∏è  Tiempo total: 31.99 min\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# 1. CONFIGURACI√ìN\n",
        "# ==========================================================\n",
        "DRIVE_PROJECT_PATH = '/content/drive/MyDrive/TFM_Cienciometria'\n",
        "MODEL_NAME = model_selector.value # <-- ¬°Aqu√≠ est√° la magia!\n",
        "\n",
        "print(f\"‚úÖ Modelo seleccionado: {MODEL_NAME}\")\n",
        "\n",
        "# Configurar rutas y directorios basados en la selecci√≥n\n",
        "if MODEL_NAME == 'mathbert':\n",
        "    TMP_DIR = os.path.join(DRIVE_PROJECT_PATH, 'data/mathbert/tmp')\n",
        "elif MODEL_NAME == 'word2vec':\n",
        "    TMP_DIR = os.path.join(DRIVE_PROJECT_PATH, 'data/word2vec/tmp') # Aseg√∫rate que esta ruta exista\n",
        "else:\n",
        "    raise ValueError(\"Modelo no reconocido. Por favor, selecciona 'mathbert' o 'word2vec'.\")\n",
        "\n",
        "# El resto de tus par√°metros pueden seguir aqu√≠\n",
        "BASE = \"TODO\"\n",
        "MESES = 120\n",
        "VENTANA_K = 150000\n",
        "ESTRICTO = True\n",
        "POOL_MIN = 50000\n",
        "PERCENTILES = [0, 5, 10, 20]\n",
        "\n",
        "# --- PAR√ÅMETRO DE OPTIMIZACI√ìN ---\n",
        "# Con el enfoque h√≠brido, puedes usar un BATCH_SIZE grande sin temor a errores de memoria.\n",
        "# 8192 o 16384 son buenos valores para una A100.\n",
        "BATCH_SIZE = 16384\n",
        "\n",
        "# ==========================================================\n",
        "# 2. L√ìGICA DE C√ÅLCULO H√çBRIDA (SOLUCI√ìN DEFINITIVA)\n",
        "# ==========================================================\n",
        "def _get_suffix(meses, k, estricto, pool_min, percentiles):\n",
        "    \"\"\"Genera el sufijo para los nombres de archivo basado en la configuraci√≥n.\"\"\"\n",
        "    parts = [f\"p{'_'.join(str(p) for p in percentiles)}\"]\n",
        "    if k is not None: parts.append(f\"k{k}\")\n",
        "    if meses is not None: parts.append(f\"m{meses}\")\n",
        "    if estricto: parts.append(\"strict\")\n",
        "    if pool_min is not None: parts.append(f\"pool{pool_min}\")\n",
        "    return \"_\".join(parts)\n",
        "\n",
        "def compute_novelty_hybrid_A100(df: pd.DataFrame, percentiles, meses=None, k=None, estricto=False, pool_min=None, batch_size=8192):\n",
        "    \"\"\"\n",
        "    Calcula la novedad usando un enfoque h√≠brido: procesa en lotes grandes para minimizar\n",
        "    la sobrecarga de Python, pero calcula la novedad de cada art√≠culo individualmente\n",
        "    dentro del lote para evitar la creaci√≥n de tensores intermedios masivos y prevenir\n",
        "    errores de OutOfMemory.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"üöÄ Realizando c√°lculos H√çBRIDOS en {device} con precisi√≥n FP16 y BATCH_SIZE={batch_size}\")\n",
        "\n",
        "    df[\"anio_mes\"] = pd.to_datetime(df[\"cover_date\"], errors=\"coerce\").dt.to_period(\"M\")\n",
        "    period_nums = df[\"anio_mes\"].apply(lambda p: p.year * 12 + p.month if pd.notna(p) else -1).to_numpy()\n",
        "\n",
        "    # Carga y normalizaci√≥n de vectores en la GPU\n",
        "    V = np.vstack(df[\"vector\"].values).astype(np.float32)\n",
        "    V_gpu = torch.from_numpy(V).to(device, dtype=torch.float16)\n",
        "    V_gpu = V_gpu / torch.norm(V_gpu, dim=1, keepdim=True).clamp(min=1e-12)\n",
        "\n",
        "    usable = df[\"vector\"].notna().to_numpy()\n",
        "    q_tensor = torch.tensor([p / 100.0 for p in percentiles], device=device, dtype=torch.float32)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    desc = f\"üîç Novedad H√çBRIDA-GPU (K={k or 'ALL'}, M={meses or 'ALL'})\"\n",
        "    # Bucle principal por lotes\n",
        "    for i in tqdm(range(0, len(df), batch_size), desc=desc):\n",
        "        batch_indices = np.arange(i, min(i + batch_size, len(df)))\n",
        "\n",
        "        # Bucle secundario dentro del lote: aqu√≠ se evitan los errores de memoria\n",
        "        for j in batch_indices:\n",
        "            if not usable[j]:\n",
        "                results.append({\"eid\": df.at[j, \"eid\"], \"pool_size\": 0, **{f\"novelty_p{p}\": np.nan for p in percentiles}})\n",
        "                continue\n",
        "\n",
        "            # C√°lculo de la ventana de comparaci√≥n (pool)\n",
        "            current = period_nums[j]\n",
        "            start = np.searchsorted(period_nums[:j], current - meses, side=\"left\") if meses else 0\n",
        "            end = np.searchsorted(period_nums[:j], current, side=\"left\") if estricto else j\n",
        "            valid_indices = np.where(usable[start:end])[0] + start\n",
        "\n",
        "            if estricto and len(valid_indices) < (pool_min or 0):\n",
        "                end = j\n",
        "                valid_indices = np.where(usable[start:end])[0] + start\n",
        "\n",
        "            if k is not None and len(valid_indices) > k:\n",
        "                valid_indices = valid_indices[-k:]\n",
        "\n",
        "            pool_size = len(valid_indices)\n",
        "\n",
        "            # C√°lculo de la novedad en la GPU\n",
        "            if pool_size == 0:\n",
        "                results.append({\"eid\": df.at[j, \"eid\"], \"pool_size\": 0, **{f\"novelty_p{p}\": np.nan for p in percentiles}})\n",
        "            else:\n",
        "                target_vector = V_gpu[j]\n",
        "                pool_vectors = V_gpu[valid_indices]\n",
        "\n",
        "                sims = pool_vectors @ target_vector\n",
        "                dists = 1.0 - sims\n",
        "\n",
        "                novelty_values = torch.quantile(dists.float(), q=q_tensor, interpolation='linear')\n",
        "\n",
        "                novelty = {f\"novelty_p{p}\": novelty_values[idx].item() for idx, p in enumerate(percentiles)}\n",
        "                results.append({\"eid\": df.at[j, \"eid\"], \"pool_size\": pool_size, **novelty})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# ==========================================================\n",
        "# 4. EJECUCI√ìN PRINCIPAL\n",
        "# ==========================================================\n",
        "if __name__ == '__main__':\n",
        "    t0 = time.time()\n",
        "    suffix = _get_suffix(MESES, VENTANA_K, ESTRICTO, POOL_MIN, PERCENTILES)\n",
        "    input_path = os.path.join(TMP_DIR, f\"04_vectores_{MODEL_NAME}_{BASE}.pkl\")\n",
        "    csv_output = os.path.join(TMP_DIR, f\"05_novelty_scores_{MODEL_NAME}_{BASE}_{suffix}.csv\")\n",
        "    pkl_output = os.path.join(TMP_DIR, f\"05_novelty_scores_{MODEL_NAME}_{BASE}_{suffix}.pkl\")\n",
        "\n",
        "    print(f\"üì¶ Cargando vectores desde: {input_path}\")\n",
        "    df_main = pd.read_pickle(input_path)\n",
        "\n",
        "    df_main = df_main.sort_values([\"cover_date\", \"eid\"]).reset_index(drop=True)\n",
        "\n",
        "    print(\"üß† Calculando √≠ndices de novedad (Optimizado H√≠brido para A100)...\")\n",
        "    # --- LLAMADA A LA FUNCI√ìN H√çBRIDA Y ROBUSTA ---\n",
        "    novelty_df = compute_novelty_hybrid_A100(\n",
        "        df_main, PERCENTILES,\n",
        "        meses=MESES, k=VENTANA_K,\n",
        "        estricto=ESTRICTO, pool_min=POOL_MIN,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    print(\"\\nüìä Resumen de novedad por percentil:\")\n",
        "    for p in PERCENTILES:\n",
        "        col = f\"novelty_p{p}\"\n",
        "        if col in novelty_df.columns:\n",
        "            s = novelty_df[col].describe()\n",
        "            print(f\"    p{p}: count={int(s['count'])} mean={s['mean']:.4f} std={s['std']:.4f} min={s['min']:.4f} max={s['max']:.4f}\")\n",
        "\n",
        "    print(\"\\nüíæ Guardando resultados...\")\n",
        "    meta_cols = [c for c in [\"eid\", \"title\", \"cover_date\", \"citedby_count\", \"doi\", \"text\"] if c in df_main.columns]\n",
        "    final_df = df_main[meta_cols].merge(novelty_df, on=\"eid\", how=\"left\")\n",
        "\n",
        "    final_df.to_csv(csv_output, index=False)\n",
        "    final_df.to_pickle(pkl_output)\n",
        "\n",
        "    elapsed = time.time() - t0\n",
        "    print(f\"\\n‚úÖ Resultados guardados en:\\n- {csv_output}\\n- {pkl_output}\")\n",
        "    print(f\"‚è±Ô∏è  Tiempo total: {elapsed/60:.2f} min\")"
      ]
    }
  ]
}